{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "rand_state = 2314\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Dense, Activation, Flatten\n",
    "from keras.layers import Dropout, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import Callback\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras import utils\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# convert our data into a rank 3 tensor\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype(np.float64)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype(np.float64)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "num_classes = 10\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "X_train, X_train_small, y_train, y_train_small = train_test_split(X_train, y_train,\n",
    "                                                  test_size=10000,\n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Tim's NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Input(shape=(28, 28, 1))\n",
    "x = Conv2D(32, 5, activation='relu')(input_image)\n",
    "x = MaxPool2D(2, strides=2)(x)\n",
    "x = Conv2D(64, 3, activation='relu')(x)\n",
    "x = MaxPool2D(2, strides=2)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "convnet = Model(inputs=input_image, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convnet.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 32s 769us/step - loss: 0.5753 - acc: 0.7950 - val_loss: 0.4398 - val_acc: 0.8452\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 32s 763us/step - loss: 0.3768 - acc: 0.8649 - val_loss: 0.3484 - val_acc: 0.8763\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 31s 747us/step - loss: 0.3196 - acc: 0.8851 - val_loss: 0.3570 - val_acc: 0.8691\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 30s 713us/step - loss: 0.2884 - acc: 0.8955 - val_loss: 0.3043 - val_acc: 0.8909\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 32s 755us/step - loss: 0.2572 - acc: 0.9060 - val_loss: 0.2866 - val_acc: 0.8989\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 33s 776us/step - loss: 0.2390 - acc: 0.9122 - val_loss: 0.3039 - val_acc: 0.8894\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 30s 719us/step - loss: 0.2182 - acc: 0.9190 - val_loss: 0.2539 - val_acc: 0.9108\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 31s 738us/step - loss: 0.2065 - acc: 0.9239 - val_loss: 0.2537 - val_acc: 0.9094\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 31s 747us/step - loss: 0.1868 - acc: 0.9304 - val_loss: 0.2483 - val_acc: 0.9151\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 33s 774us/step - loss: 0.1680 - acc: 0.9388 - val_loss: 0.2633 - val_acc: 0.9081\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 34s 800us/step - loss: 0.1573 - acc: 0.9419 - val_loss: 0.2467 - val_acc: 0.9147\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 32s 751us/step - loss: 0.1428 - acc: 0.9475 - val_loss: 0.2697 - val_acc: 0.9145\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 30s 725us/step - loss: 0.1307 - acc: 0.9515 - val_loss: 0.2922 - val_acc: 0.8997\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 32s 758us/step - loss: 0.1210 - acc: 0.9550 - val_loss: 0.2720 - val_acc: 0.9122\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 31s 741us/step - loss: 0.1120 - acc: 0.9581 - val_loss: 0.2951 - val_acc: 0.9017\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 30s 714us/step - loss: 0.0998 - acc: 0.9628 - val_loss: 0.2681 - val_acc: 0.9178\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 32s 767us/step - loss: 0.0884 - acc: 0.9674 - val_loss: 0.2791 - val_acc: 0.9156\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 33s 779us/step - loss: 0.0775 - acc: 0.9709 - val_loss: 0.3332 - val_acc: 0.9083\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 31s 727us/step - loss: 0.0732 - acc: 0.9744 - val_loss: 0.2948 - val_acc: 0.9175\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 32s 755us/step - loss: 0.0625 - acc: 0.9774 - val_loss: 0.3207 - val_acc: 0.9109\n"
     ]
    }
   ],
   "source": [
    "history_callback = convnet.fit(X_train, y_train,\n",
    "                               batch_size=128,\n",
    "                               epochs=20, verbose=1,\n",
    "                               validation_split=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbMAAAD8CAYAAAD9lEqKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXjkzzCrkGQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(history_callback.history)\n",
    "df[['acc', 'val_acc']].plot()\n",
    "plt.ylabel(\"accuracy\")\n",
    "df[['loss', 'val_loss']].plot(linestyle='--', ax=plt.twinx())\n",
    "plt.ylabel(\"loss\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Convolution and Dropout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_image = Input(shape=(28, 28, 1))\n",
    "x = Conv2D(16, 6, activation='relu')(input_image)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Conv2D(32, 3, activation='relu')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "convnet = Model(inputs=input_image, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.4139 - acc: 0.8506 - val_loss: 0.3936 - val_acc: 0.8610\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.3518 - acc: 0.8727 - val_loss: 0.3874 - val_acc: 0.8630\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.3067 - acc: 0.8859 - val_loss: 0.3882 - val_acc: 0.8627\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.2655 - acc: 0.9027 - val_loss: 0.3872 - val_acc: 0.8650\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 9s 1ms/step - loss: 0.2535 - acc: 0.9097 - val_loss: 0.3665 - val_acc: 0.8687\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.2150 - acc: 0.9223 - val_loss: 0.3647 - val_acc: 0.8737\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.1788 - acc: 0.9347 - val_loss: 0.3797 - val_acc: 0.8793\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 11s 2ms/step - loss: 0.1524 - acc: 0.9487 - val_loss: 0.4128 - val_acc: 0.8690\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 11s 2ms/step - loss: 0.1376 - acc: 0.9509 - val_loss: 0.3850 - val_acc: 0.8770\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.1129 - acc: 0.9601 - val_loss: 0.4056 - val_acc: 0.8783\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.1169 - acc: 0.9571 - val_loss: 0.4484 - val_acc: 0.8777\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.0942 - acc: 0.9656 - val_loss: 0.4540 - val_acc: 0.8760\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.0826 - acc: 0.9723 - val_loss: 0.4410 - val_acc: 0.8810\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.0656 - acc: 0.9786 - val_loss: 0.4589 - val_acc: 0.8803\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.0575 - acc: 0.9804 - val_loss: 0.4901 - val_acc: 0.8723\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.0580 - acc: 0.9823 - val_loss: 0.4883 - val_acc: 0.8763\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.0445 - acc: 0.9864 - val_loss: 0.5014 - val_acc: 0.8837\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.0324 - acc: 0.9906 - val_loss: 0.5080 - val_acc: 0.8827\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.0235 - acc: 0.9939 - val_loss: 0.5260 - val_acc: 0.8807\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.0222 - acc: 0.9949 - val_loss: 0.5581 - val_acc: 0.8747\n"
     ]
    }
   ],
   "source": [
    "history_callback = convnet.fit(X_train_small, y_train_small,\n",
    "                               batch_size=128,\n",
    "                               epochs=20, verbose=1,\n",
    "                               validation_split=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add more Dropout layers and reduce nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_image = Input(shape=(28, 28, 1))\n",
    "x = Conv2D(16, 6, activation='relu')(input_image)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv2D(32, 3, activation='relu')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(40, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "convnet = Model(inputs=input_image, outputs=x)\n",
    "\n",
    "convnet.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 1.1535 - acc: 0.6100 - val_loss: 0.6810 - val_acc: 0.7690\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 6s 912us/step - loss: 0.6999 - acc: 0.7609 - val_loss: 0.5385 - val_acc: 0.8133\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 7s 951us/step - loss: 0.5764 - acc: 0.7970 - val_loss: 0.4741 - val_acc: 0.8367\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 7s 946us/step - loss: 0.5036 - acc: 0.8214 - val_loss: 0.4606 - val_acc: 0.8430\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 7s 935us/step - loss: 0.4660 - acc: 0.8341 - val_loss: 0.4319 - val_acc: 0.8510\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 7s 948us/step - loss: 0.4351 - acc: 0.8486 - val_loss: 0.4113 - val_acc: 0.8560\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.3900 - acc: 0.8611 - val_loss: 0.3936 - val_acc: 0.8650\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 7s 945us/step - loss: 0.3740 - acc: 0.8634 - val_loss: 0.3959 - val_acc: 0.8657\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 7s 952us/step - loss: 0.3593 - acc: 0.8691 - val_loss: 0.4081 - val_acc: 0.8640\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.3316 - acc: 0.8784 - val_loss: 0.3841 - val_acc: 0.8713\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 7s 954us/step - loss: 0.3030 - acc: 0.8857 - val_loss: 0.3815 - val_acc: 0.8693\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 7s 944us/step - loss: 0.2978 - acc: 0.8923 - val_loss: 0.3835 - val_acc: 0.8727\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 7s 930us/step - loss: 0.2723 - acc: 0.9011 - val_loss: 0.3897 - val_acc: 0.8727\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 7s 964us/step - loss: 0.2689 - acc: 0.8981 - val_loss: 0.3791 - val_acc: 0.8747\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.2434 - acc: 0.9071 - val_loss: 0.3879 - val_acc: 0.8697\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 7s 957us/step - loss: 0.2359 - acc: 0.9109 - val_loss: 0.3804 - val_acc: 0.8780\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.2278 - acc: 0.9131 - val_loss: 0.4175 - val_acc: 0.8730\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 7s 985us/step - loss: 0.2226 - acc: 0.9160 - val_loss: 0.4002 - val_acc: 0.8723\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 7s 973us/step - loss: 0.2088 - acc: 0.9211 - val_loss: 0.4036 - val_acc: 0.8707\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 7s 956us/step - loss: 0.1964 - acc: 0.9236 - val_loss: 0.3921 - val_acc: 0.8753\n"
     ]
    }
   ],
   "source": [
    "history_callback = convnet.fit(X_train_small, y_train_small,\n",
    "                               batch_size=128,\n",
    "                               epochs=20, verbose=1,\n",
    "                               validation_split=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use MaxPool2D but no Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_image = Input(shape=(28, 28, 1))\n",
    "x = MaxPool2D(2, strides=2)(input_image)\n",
    "x = MaxPool2D(2, strides=2)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(100, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "convnet = Model(inputs=input_image, outputs=x)\n",
    "\n",
    "convnet.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 1s 112us/step - loss: 1.8743 - acc: 0.3687 - val_loss: 1.4143 - val_acc: 0.5390\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 1.2876 - acc: 0.5464 - val_loss: 1.0862 - val_acc: 0.6147\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 1.0902 - acc: 0.5914 - val_loss: 0.9601 - val_acc: 0.6627\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 0.9893 - acc: 0.6246 - val_loss: 0.8977 - val_acc: 0.6697\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 1s 76us/step - loss: 0.9330 - acc: 0.6510 - val_loss: 0.8483 - val_acc: 0.6877\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 0.8891 - acc: 0.6684 - val_loss: 0.8216 - val_acc: 0.7013\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 0.8574 - acc: 0.6713 - val_loss: 0.7924 - val_acc: 0.7123\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 0s 62us/step - loss: 0.8333 - acc: 0.6843 - val_loss: 0.7778 - val_acc: 0.7163\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.8148 - acc: 0.6913 - val_loss: 0.7582 - val_acc: 0.7227\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 0.8007 - acc: 0.6947 - val_loss: 0.7508 - val_acc: 0.7210\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 1s 96us/step - loss: 0.7831 - acc: 0.7017 - val_loss: 0.7358 - val_acc: 0.7273\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 0s 64us/step - loss: 0.7640 - acc: 0.7104 - val_loss: 0.7242 - val_acc: 0.7367\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 0s 71us/step - loss: 0.7563 - acc: 0.7073 - val_loss: 0.7191 - val_acc: 0.7360\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 0.7440 - acc: 0.7134 - val_loss: 0.7109 - val_acc: 0.7330\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 0.7346 - acc: 0.7207 - val_loss: 0.6998 - val_acc: 0.7380\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 1s 76us/step - loss: 0.7192 - acc: 0.7240 - val_loss: 0.6935 - val_acc: 0.7533\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.7126 - acc: 0.7287 - val_loss: 0.6935 - val_acc: 0.7430\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 1s 72us/step - loss: 0.7106 - acc: 0.7260 - val_loss: 0.6826 - val_acc: 0.7483\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 1s 84us/step - loss: 0.6986 - acc: 0.7326 - val_loss: 0.6760 - val_acc: 0.7480\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 1s 110us/step - loss: 0.6972 - acc: 0.7383 - val_loss: 0.6762 - val_acc: 0.7460\n"
     ]
    }
   ],
   "source": [
    "history_callback = convnet.fit(X_train_small, y_train_small,\n",
    "                               batch_size=128,\n",
    "                               epochs=20, verbose=1,\n",
    "                               validation_split=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use BatchNormalization and Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_image = Input(shape=(28, 28, 1))\n",
    "x = Conv2D(16, 6, activation='relu')(input_image)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(32, 4, activation='relu')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(100, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "convnet = Model(inputs=input_image, outputs=x)\n",
    "\n",
    "convnet.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 11s 2ms/step - loss: 0.7812 - acc: 0.7251 - val_loss: 0.4909 - val_acc: 0.8287\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.4321 - acc: 0.8439 - val_loss: 0.4374 - val_acc: 0.8380\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.3511 - acc: 0.8693 - val_loss: 0.4007 - val_acc: 0.8540\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.2846 - acc: 0.8913 - val_loss: 0.4046 - val_acc: 0.8613\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.2285 - acc: 0.9104 - val_loss: 0.3899 - val_acc: 0.8567\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.1896 - acc: 0.9306 - val_loss: 0.4131 - val_acc: 0.8593\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.1642 - acc: 0.9393 - val_loss: 0.4528 - val_acc: 0.8673\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.1386 - acc: 0.9486 - val_loss: 0.4504 - val_acc: 0.8650\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.1151 - acc: 0.9580 - val_loss: 0.4785 - val_acc: 0.8703\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.0907 - acc: 0.9686 - val_loss: 0.5159 - val_acc: 0.8667\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.0796 - acc: 0.9709 - val_loss: 0.5145 - val_acc: 0.8683\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.0757 - acc: 0.9721 - val_loss: 0.5210 - val_acc: 0.8660\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.0592 - acc: 0.9806 - val_loss: 0.5373 - val_acc: 0.8647\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.0647 - acc: 0.9783 - val_loss: 0.5136 - val_acc: 0.8733\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 11s 2ms/step - loss: 0.0521 - acc: 0.9834 - val_loss: 0.5593 - val_acc: 0.8617\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 11s 2ms/step - loss: 0.0432 - acc: 0.9874 - val_loss: 0.5464 - val_acc: 0.8680\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.0311 - acc: 0.9897 - val_loss: 0.6176 - val_acc: 0.8707\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 11s 2ms/step - loss: 0.0284 - acc: 0.9917 - val_loss: 0.5706 - val_acc: 0.8747\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 10s 1ms/step - loss: 0.0311 - acc: 0.9894 - val_loss: 0.5817 - val_acc: 0.8697\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 11s 2ms/step - loss: 0.0214 - acc: 0.9939 - val_loss: 0.6267 - val_acc: 0.8723\n"
     ]
    }
   ],
   "source": [
    "history_callback = convnet.fit(X_train_small, y_train_small,\n",
    "                               batch_size=128,\n",
    "                               epochs=20, verbose=1,\n",
    "                               validation_split=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test a network with larger convolutional filters (takes long time to train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_image = Input(shape=(28, 28, 1))\n",
    "x = Conv2D(64, 6, activation='relu')(input_image)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(32, 4, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(100, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "convnet = Model(inputs=input_image, outputs=x)\n",
    "\n",
    "convnet.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 39s 6ms/step - loss: 0.8857 - acc: 0.7229 - val_loss: 0.5480 - val_acc: 0.8103\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 38s 5ms/step - loss: 0.4982 - acc: 0.8213 - val_loss: 0.6788 - val_acc: 0.8083\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 41s 6ms/step - loss: 0.3916 - acc: 0.8537 - val_loss: 0.4977 - val_acc: 0.8407\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 38s 5ms/step - loss: 0.3270 - acc: 0.8799 - val_loss: 0.5175 - val_acc: 0.8293\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 37s 5ms/step - loss: 0.2664 - acc: 0.8976 - val_loss: 0.4717 - val_acc: 0.8493\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 40s 6ms/step - loss: 0.2359 - acc: 0.9067 - val_loss: 0.4730 - val_acc: 0.8460\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 38s 5ms/step - loss: 0.2126 - acc: 0.9167 - val_loss: 0.5423 - val_acc: 0.8500\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 37s 5ms/step - loss: 0.1865 - acc: 0.9256 - val_loss: 0.5618 - val_acc: 0.8643\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 36s 5ms/step - loss: 0.1763 - acc: 0.9311 - val_loss: 0.5607 - val_acc: 0.8620\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 38s 5ms/step - loss: 0.1572 - acc: 0.9373 - val_loss: 0.5552 - val_acc: 0.8583\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 39s 6ms/step - loss: 0.1348 - acc: 0.9491 - val_loss: 0.6257 - val_acc: 0.8550\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 40s 6ms/step - loss: 0.1133 - acc: 0.9557 - val_loss: 0.5914 - val_acc: 0.8603\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 39s 6ms/step - loss: 0.1010 - acc: 0.9609 - val_loss: 0.5675 - val_acc: 0.8603\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 41s 6ms/step - loss: 0.0957 - acc: 0.9643 - val_loss: 0.5811 - val_acc: 0.8590\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 40s 6ms/step - loss: 0.0772 - acc: 0.9716 - val_loss: 0.5612 - val_acc: 0.8723\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 36s 5ms/step - loss: 0.0745 - acc: 0.9730 - val_loss: 0.6494 - val_acc: 0.8663\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 38s 5ms/step - loss: 0.0734 - acc: 0.9719 - val_loss: 0.5795 - val_acc: 0.8730\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 37s 5ms/step - loss: 0.0625 - acc: 0.9769 - val_loss: 0.5972 - val_acc: 0.8693\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 37s 5ms/step - loss: 0.0549 - acc: 0.9800 - val_loss: 0.6983 - val_acc: 0.8737\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 38s 5ms/step - loss: 0.0482 - acc: 0.9830 - val_loss: 0.6180 - val_acc: 0.8693\n"
     ]
    }
   ],
   "source": [
    "history_callback = convnet.fit(X_train_small, y_train_small,\n",
    "                               batch_size=128,\n",
    "                               epochs=20, verbose=1,\n",
    "                               validation_split=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_image = Input(shape=(28, 28, 1))\n",
    "x = Conv2D(36, 6, activation='relu')(input_image)\n",
    "x = MaxPool2D(3, strides=2)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "convnet = Model(inputs=input_image, outputs=x)\n",
    "\n",
    "convnet.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 3000 samples\n",
      "Epoch 1/20\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.7758 - acc: 0.7403 - val_loss: 0.4688 - val_acc: 0.8287\n",
      "Epoch 2/20\n",
      "7000/7000 [==============================] - 7s 949us/step - loss: 0.4560 - acc: 0.8344 - val_loss: 0.4271 - val_acc: 0.8437\n",
      "Epoch 3/20\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.3813 - acc: 0.8557 - val_loss: 0.4075 - val_acc: 0.8543\n",
      "Epoch 4/20\n",
      "7000/7000 [==============================] - 7s 988us/step - loss: 0.3268 - acc: 0.8764 - val_loss: 0.3758 - val_acc: 0.8723\n",
      "Epoch 5/20\n",
      "7000/7000 [==============================] - 6s 905us/step - loss: 0.2959 - acc: 0.8870 - val_loss: 0.3656 - val_acc: 0.8767\n",
      "Epoch 6/20\n",
      "7000/7000 [==============================] - 7s 932us/step - loss: 0.2802 - acc: 0.8967 - val_loss: 0.3475 - val_acc: 0.8780\n",
      "Epoch 7/20\n",
      "7000/7000 [==============================] - 6s 920us/step - loss: 0.2355 - acc: 0.9081 - val_loss: 0.3510 - val_acc: 0.8773\n",
      "Epoch 8/20\n",
      "7000/7000 [==============================] - 7s 967us/step - loss: 0.2218 - acc: 0.9154 - val_loss: 0.3713 - val_acc: 0.8810\n",
      "Epoch 9/20\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.2100 - acc: 0.9203 - val_loss: 0.3538 - val_acc: 0.8830\n",
      "Epoch 10/20\n",
      "7000/7000 [==============================] - 7s 948us/step - loss: 0.1899 - acc: 0.9307 - val_loss: 0.4222 - val_acc: 0.8713\n",
      "Epoch 11/20\n",
      "7000/7000 [==============================] - 7s 936us/step - loss: 0.1753 - acc: 0.9337 - val_loss: 0.3661 - val_acc: 0.8910\n",
      "Epoch 12/20\n",
      "7000/7000 [==============================] - 6s 927us/step - loss: 0.1652 - acc: 0.9377 - val_loss: 0.3521 - val_acc: 0.8897\n",
      "Epoch 13/20\n",
      "7000/7000 [==============================] - 7s 1ms/step - loss: 0.1743 - acc: 0.9347 - val_loss: 0.4099 - val_acc: 0.8767\n",
      "Epoch 14/20\n",
      "7000/7000 [==============================] - 7s 954us/step - loss: 0.1436 - acc: 0.9479 - val_loss: 0.4108 - val_acc: 0.8870\n",
      "Epoch 15/20\n",
      "7000/7000 [==============================] - 7s 956us/step - loss: 0.1422 - acc: 0.9457 - val_loss: 0.4072 - val_acc: 0.8843\n",
      "Epoch 16/20\n",
      "7000/7000 [==============================] - 7s 991us/step - loss: 0.1333 - acc: 0.9501 - val_loss: 0.4530 - val_acc: 0.8773\n",
      "Epoch 17/20\n",
      "7000/7000 [==============================] - 7s 953us/step - loss: 0.1349 - acc: 0.9501 - val_loss: 0.3673 - val_acc: 0.8883\n",
      "Epoch 18/20\n",
      "7000/7000 [==============================] - 7s 967us/step - loss: 0.1354 - acc: 0.9481 - val_loss: 0.3784 - val_acc: 0.8957\n",
      "Epoch 19/20\n",
      "7000/7000 [==============================] - 7s 934us/step - loss: 0.1178 - acc: 0.9561 - val_loss: 0.4397 - val_acc: 0.8783\n",
      "Epoch 20/20\n",
      "7000/7000 [==============================] - 7s 948us/step - loss: 0.1133 - acc: 0.9571 - val_loss: 0.3921 - val_acc: 0.8957\n"
     ]
    }
   ],
   "source": [
    "history_callback = convnet.fit(X_train_small, y_train_small,\n",
    "                               batch_size=128,\n",
    "                               epochs=20, verbose=1,\n",
    "                               validation_split=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Conclusion ** The various layers have some effect on the training speed of the NN, however, eventually all the tested solutions overfit the model parameters, even with higher fractions in the Dropuout layers and the accuracy in the test data remains ~ 90%. This was the value also achieved with the dense network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
